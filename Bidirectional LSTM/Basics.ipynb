{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Bidirectional LSTM in Pytorch**"
      ],
      "metadata": {
        "id": "Old9f6GURNrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QmGPGx20OZ0z"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input Parameters\n",
        "\n",
        "#input_size = The number of expected features in the input. Feature dimension\n",
        "\n",
        "#hidden_size = Number of units in the hidden state. The number of features in the hidden state h\n",
        "\n",
        "#num_layers = Number of vertical stacks of hidden layers\n",
        "\n",
        "#batch_first = True, it means input shape of the data to the LSTM is (batch_size, seq_len, features)\n",
        "\n",
        "#bidirectional = True, it menas that LSTM is bidirectional"
      ],
      "metadata": {
        "id": "5YndUJJ1RTyF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nn.LSTM( input_size, hidden_size, num_layers, batch_first = True, bidirectional = True )"
      ],
      "metadata": {
        "id": "pBIkOO_KRocJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When batch_first = True"
      ],
      "metadata": {
        "id": "yytLK634R2R4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set parameters\n",
        "input_size  =  1\n",
        "hidden_size = 16\n",
        "num_layers  =  1\n",
        "\n",
        "#Create Model\n",
        "Bi_lstmModel = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True, bidirectional = True)\n",
        "Bi_lstmModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6MTNcjjR5RV",
        "outputId": "981d2632-d272-47f4-fef3-3ed0ab2656b9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(1, 16, batch_first=True, bidirectional=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating data\n",
        "seqlength = 5 # sequence length or timesteps\n",
        "batchsize = 4 # Batch size or Number of samples\n",
        "\n",
        "# create some random data\n",
        "X = torch.rand(batchsize, seqlength, input_size) # Because batch_first is true, therefore (N,T,D)\n",
        "                                                 # N = Batch size or Number of samples\n",
        "                                                 # T = sequence length or timesteps\n",
        "                                                 # D = Feature Dimension or Inputsize"
      ],
      "metadata": {
        "id": "4EWEmn85SIfe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get output from model\n",
        "y,(h,c) = Bi_lstmModel(X) #hidden_inputs)\n",
        "\n",
        "print(f'Input shape: {list(X.shape)}')            # Batchsize x seqlen x feature dim  OR N x T x D\n",
        "print(f'Hidden shape: {list(h.shape)}')           # 2 * numlayers x Batchsize x hiddensize\n",
        "print(f'Cell memory shape: {list(c.shape)}')      # 2 * numlayers x Batchsize x hiddensize\n",
        "print(f'Output shape: {list(y.shape)}')           # batchsize x seqlen x 2 * hiddensize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOGRi38zSQZt",
        "outputId": "c5ba3a6c-9353-4973-9fe3-f61a014bdec2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [4, 5, 1]\n",
            "Hidden shape: [2, 4, 16]\n",
            "Cell memory shape: [2, 4, 16]\n",
            "Output shape: [4, 5, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When batch_first = False (defalut)"
      ],
      "metadata": {
        "id": "Gt1zTZwISXEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Bi_lstmModel2 = nn.LSTM(input_size, hidden_size, num_layers, bidirectional = True)\n",
        "Bi_lstmModel2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAfSf2VRSZFu",
        "outputId": "da2c11c5-3e0e-4865-96b9-8f0e8968cccb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(1, 16, bidirectional=True)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(seqlength, batchsize, input_size)"
      ],
      "metadata": {
        "id": "71ujh6k6SfIr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y,(h,c) = Bi_lstmModel2(X) #hidden_inputs)\n",
        "\n",
        "print(f'Input shape: {list(X.shape)}')            # seqlen x Batchsize x feature dim  OR N x T x D\n",
        "print(f'Hidden shape: {list(h.shape)}')           # 2 * numlayers x Batchsize x hiddensize\n",
        "print(f'Cell memory shape: {list(c.shape)}')      # 2 * numlayers x Batchsize x hiddensize\n",
        "print(f'Output shape: {list(y.shape)}')           # seqlen x Batchsize x 2 * hiddensize"
      ],
      "metadata": {
        "id": "gzzXGLvcShSb",
        "outputId": "61650fe1-61e5-4256-c769-0f6926596489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [5, 4, 1]\n",
            "Hidden shape: [2, 4, 16]\n",
            "Cell memory shape: [2, 4, 16]\n",
            "Output shape: [5, 4, 32]\n"
          ]
        }
      ]
    }
  ]
}