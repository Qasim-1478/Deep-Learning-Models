{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HMfLr6s4rMW6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set LSTM parameters\n",
        "input_size = 9\n",
        "hidden_size= 16\n",
        "num_layers = 2\n",
        "\n",
        "#Create Instance of LSTM\n",
        "lstm = nn.LSTM(input_size,hidden_size,num_layers, batch_first=True)\n",
        "lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j88fG7N7rbfF",
        "outputId": "9696b824-cd11-495f-f2d5-692a8bf23e07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(9, 16, num_layers=2, batch_first=True)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the data\n",
        "\n",
        "seqlength=5\n",
        "batchsize=2\n",
        "\n",
        "X=torch.rand(batchsize,seqlength,input_size)\n",
        "\n",
        "#Create initial hidden states\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size) #Hidden State\n",
        "C = torch.zeros(num_layers,batchsize,hidden_size) #Memory State\n",
        "\n",
        "hidden_inputs = (H,C)\n",
        "\n",
        "y,(h,c)= lstm(X,hidden_inputs)\n",
        "print('Input Shape:', X.shape)\n",
        "print('Output Shape:', y.shape)\n",
        "print('Hidden State Shape:', h.shape)\n",
        "print('Memory State Shape:', c.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8ieMIoerx9Y",
        "outputId": "940fc507-975c-4b8d-969c-dc803f8caf78"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Shape: torch.Size([2, 5, 9])\n",
            "Output Shape: torch.Size([2, 5, 16])\n",
            "Hidden State Shape: torch.Size([2, 2, 16])\n",
            "Memory State Shape: torch.Size([2, 2, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create LSTM using class\n",
        "\n",
        "class LSTM_model(nn.Module):\n",
        "  def __init__(self,input_size,num_hidden, num_layers):\n",
        "    super().__init__()\n",
        "\n",
        "    #Define parameters\n",
        "\n",
        "    self.input_size = input_size\n",
        "    self.num_hidden = num_hidden\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    #The LSTM layer\n",
        "    self.lstm = nn.LSTM(input_size,num_hidden,num_layers, batch_first=True)\n",
        "\n",
        "    #Output Layer (For Prediction or classification)\n",
        "    self.out = nn.Linear(num_hidden,1) # 1 is the no. of categories or the output size\n",
        "\n",
        "  def forward(self,x): #There is no hidden at the input of forward, so we cant input hidden while training the model\n",
        "\n",
        "    #Passing data through the LSTM\n",
        "    y,(h,c)= self.lstm(x)\n",
        "\n",
        "    #Pass the LSTM output through the output layer\n",
        "    out=self.out(y)\n",
        "\n",
        "    return out, (h,c)\n",
        "\n"
      ],
      "metadata": {
        "id": "9Yh4NY4rscMP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Instance of LSTM model\n",
        "model = LSTM_model(input_size,hidden_size,num_layers)\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZjntLPCuCTF",
        "outputId": "64e64ac7-9760-49fd-cea7-05b031b6ecae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM_model(\n",
              "  (lstm): LSTM(9, 16, num_layers=2, batch_first=True)\n",
              "  (out): Linear(in_features=16, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create data and run the LSTM\n",
        "\n",
        "X = torch.rand(batchsize,seqlength,input_size)\n",
        "y = torch.rand(batchsize,seqlength,1)\n",
        "\n",
        "\n",
        "ypred, (h,c) = model(X)\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "print(\" \")\n",
        "print(\" \")\n",
        "\n",
        "lossfunc = nn.MSELoss()\n",
        "lossfunc(ypred,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWLOSERluLNy",
        "outputId": "8dc6f616-20de-41b1-e6d6-0c8c1dfe36fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            " \n",
            "torch.Size([2, 5, 9])\n",
            "torch.Size([2, 5, 1])\n",
            " \n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2008, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h.shape # Hidden cell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kKMUdKHuhJr",
        "outputId": "4b60d305-de4a-4c76-c768-d8eba595921f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.shape # Memory cell"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5BaIfoFulIy",
        "outputId": "e4febdcd-a18d-448f-a122-54c7d5e831c9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}