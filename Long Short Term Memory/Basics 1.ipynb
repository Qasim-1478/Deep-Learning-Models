{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Data/Input Parameters for LSTM**"
      ],
      "metadata": {
        "id": "qWzUbFaNmCny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "QZLh32fZmJz4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input Layer of LSTM Layer\n",
        "\n",
        "#nn.LSTM( input_size, hidden_size, num_layers, batch_first = True )\n",
        "\n",
        "#input_size = The number of expected features in the input. Feature dimensions\n",
        "\n",
        "#hidden_size = Number of units in the hidden state. The number of features in the hidden state h\n",
        "\n",
        "#num_layers = Number of vertical stacks of hidden layers\n",
        "\n",
        "#batch_first = True, it means input shape of the data to the LSTM is (batch_size, seq_len, features)"
      ],
      "metadata": {
        "id": "_7L7MbdhobXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#When batch_first= True\n",
        "\n",
        "# Set the lSTM parameters\n",
        "\n",
        "input_size  =  1\n",
        "hidden_size = 16\n",
        "num_layers  =  2\n",
        "\n",
        "# create an LSTM instance\n",
        "\n",
        "lstmModel = nn.LSTM(input_size, hidden_size, num_layers, batch_first = True)\n",
        "lstmModel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKNMZyqeouCj",
        "outputId": "2ff17a5d-f69b-4fc4-ce57-cb1f2a7f695c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(1, 16, num_layers=2, batch_first=True)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the data parameters\n",
        "seqlength = 5 # sequence length or timesteps\n",
        "batchsize = 2 # Batch size or Number of samples\n",
        "\n",
        "# create some random data\n",
        "X = torch.rand(batchsize, seqlength, input_size) # Because batch_first is true, therefore (N,T,D)\n",
        "                                                 # N = Batch size or Number of samples\n",
        "                                                 # T = sequence length or timesteps\n",
        "                                                 # D = Feature Dimension or Inputsize\n",
        "\n",
        "# Initialized hidden states as zeros\n",
        "\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "C = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "\n",
        "\n",
        "# The hidden input is actually a tuple of (hidden, cell)\n",
        "\n",
        "hidden_inputs = (H,C)\n",
        "\n",
        "\n",
        "y,(h,c) = lstmModel(X, hidden_inputs)\n",
        "\n",
        "print(f'Input shape: {list(X.shape)}')     # Batchsize x seqlen x feature dim  OR N x T x D\n",
        "print(f'Hidden shape: {list(h.shape)}')    # numlayers x Batchsize x hiddensize\n",
        "print(f'Cell memory shape: {list(c.shape)}')      # numlayers x Batchsize x hiddensize\n",
        "print(f'Output shape: {list(y.shape)}')    # Batchsize x seqlen x hiddensize (features in hidden state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFN_bN8GpEaP",
        "outputId": "50acd2c0-87cc-46f0-d010-558d276d44d1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [2, 5, 1]\n",
            "Hidden shape: [2, 2, 16]\n",
            "Cell memory shape: [2, 2, 16]\n",
            "Output shape: [2, 5, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#When batch_size = False (Default)\n",
        "\n",
        "input_size  =  4\n",
        "hidden_size = 16\n",
        "num_layers  =  2\n",
        "\n",
        "# create an LSTM instance\n",
        "lstm = nn.LSTM(input_size, hidden_size, num_layers) # default batch_first = False\n",
        "lstm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1K8HbpCpi4U",
        "outputId": "ea998a4e-b9f3-4184-9fd3-d49d2c1df966"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LSTM(4, 16, num_layers=2)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data parameters\n",
        "seqlength = 5 # sequence length or timesteps\n",
        "batchsize = 3 # Batch size or Number of samples\n",
        "\n",
        "# Create some data\n",
        "X = torch.rand(seqlength, batchsize, input_size)\n",
        "\n",
        "# Create initial hidden states (typically initialized as zeros)\n",
        "\n",
        "H = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "C = torch.zeros(num_layers,batchsize,hidden_size)\n",
        "\n",
        "# the input is actually a tuple of (hidden,cell)\n",
        "hidden_inputs = (H,C)\n",
        "\n",
        "# run some data through the model and show the output sizes\n",
        "y, (h,c) = lstm(X, hidden_inputs)\n",
        "print(f'Input shape: {list(X.shape)}')    # seqlength x Batchsize x feature dimension\n",
        "print(f'Hidden shape: {list(h.shape)}')   # numlayers x Batchsize x hiddensize\n",
        "print(f'Cell memory shape: {list(c.shape)}')     # numlayers x Batchsize x hiddensize\n",
        "print(f'Output shape: {list(y.shape)}')   # seqlen x Batchsize x hiddensize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VCaO613pw92",
        "outputId": "a9f35ead-beb1-4843-d738-0d510797758b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [5, 3, 4]\n",
            "Hidden shape: [2, 3, 16]\n",
            "Cell memory shape: [2, 3, 16]\n",
            "Output shape: [5, 3, 16]\n"
          ]
        }
      ]
    }
  ]
}