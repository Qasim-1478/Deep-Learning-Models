{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "_cw63qWKaBl2"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MjaGF2eaDhV",
    "outputId": "1896b3be-b54b-4628-e18c-f0e0b7ab12a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Instance of the whole transformer\n",
    "transformer_model = nn.Transformer(d_model = 256, nhead = 8, num_encoder_layers = 6, num_decoder_layers = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkeVNzdzaJM4",
    "outputId": "878e1715-0628-477d-feed-93cd2a5915c7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-NncTg0LaLKX"
   },
   "outputs": [],
   "source": [
    "#Creating source and target val for the transformer\n",
    "src = torch.rand((200, 256))\n",
    "tgt = torch.rand((1, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ROiY3FsaTXr",
    "outputId": "dceabe15-a432-474d-f11c-87dafe175fee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3713,  0.2296,  1.7258,  2.3029, -0.2078, -0.8084,  1.0420, -0.9571,\n",
       "          0.1131,  0.8507, -1.2768,  0.6044, -1.3695, -0.6861, -0.5056,  0.7889,\n",
       "          0.8572,  1.1860, -1.1890, -2.5578, -1.0491,  0.8915, -0.5077, -1.1907,\n",
       "          0.5053, -0.4626, -1.5392,  1.7358, -1.7539, -0.7621, -0.9709, -1.5786,\n",
       "          0.6341, -0.6800,  0.8008,  0.3163,  2.5623,  1.3184, -0.1679,  0.3813,\n",
       "          0.3217,  0.4185, -0.6304,  1.1273,  1.9432, -0.7149,  0.1213, -1.3287,\n",
       "         -0.3047,  0.2903, -0.6089, -0.9955,  1.0289, -0.1906, -0.2967,  1.2125,\n",
       "          1.4016, -0.3979,  0.1225, -0.2759,  0.0548,  0.3262, -1.1201, -0.3509,\n",
       "          0.2746, -0.6598,  1.1167, -0.9078, -1.1136,  0.3026, -0.4012, -0.5332,\n",
       "         -0.1706, -0.4689, -1.2533, -1.4443,  0.8030, -1.3830, -2.2261, -1.4696,\n",
       "          1.1140, -0.6927,  0.2865, -0.2680,  0.0863, -0.5196,  2.3716, -0.4520,\n",
       "          2.5437, -0.1287,  1.2697,  0.3001, -0.2032, -0.5319,  1.4072,  1.2383,\n",
       "          0.3729,  0.4257, -0.0277,  2.1954, -1.1005, -0.3469, -0.9703, -1.5382,\n",
       "         -0.2820,  1.0945,  0.6978, -0.0341,  1.8582, -1.0094, -0.3710,  0.2840,\n",
       "          0.0188,  1.4344, -0.5085, -1.2876, -0.0255,  0.8364,  0.9710, -0.2969,\n",
       "          1.0008,  0.6325, -0.2748, -0.4406,  1.9150,  0.6087, -0.4323, -0.4579,\n",
       "         -1.2458,  0.7487,  0.3101,  0.8403,  0.6455, -0.0736, -2.1992,  1.1830,\n",
       "         -0.9820,  0.9498,  0.5622, -1.4746,  1.8952,  1.8260, -0.4008, -2.0951,\n",
       "          1.1322, -1.3357, -1.3664, -0.0757, -0.1168,  0.2784,  1.7366,  1.3793,\n",
       "          0.8039,  0.9192,  0.0785, -0.2391, -0.6593,  0.4376, -0.0579, -0.2472,\n",
       "          0.5963,  0.6010,  0.0913, -0.3584, -0.6036,  1.6033, -0.8471, -1.6573,\n",
       "          0.2581, -1.1485, -0.8158,  1.3519, -0.5839, -0.9865,  1.6098, -1.4293,\n",
       "          1.2580,  0.1042,  0.0390, -0.8389, -0.2180,  1.0393,  0.0226, -1.2250,\n",
       "          0.0578, -1.0984, -1.2644,  0.7612,  0.4844, -0.8836,  0.3015,  0.4150,\n",
       "         -0.9334,  1.3251, -1.5190, -0.7973,  1.0202, -1.6335,  1.2148,  0.9230,\n",
       "          0.4532,  0.6882, -0.4832,  0.6278,  0.8097,  1.1309, -0.2749, -1.0921,\n",
       "         -0.6673,  0.5100,  1.4951, -0.0185, -0.8645,  0.4952,  0.0751, -0.3756,\n",
       "          0.1275, -0.1654,  1.1484,  0.1121, -0.7085, -1.4713, -1.7067, -0.5343,\n",
       "         -0.1922,  0.1691, -0.2698, -0.4651,  0.4165,  0.0999,  0.9259,  1.3164,\n",
       "          1.1834,  0.5063,  0.1458,  1.4411, -2.3810, -0.2973,  0.8225,  0.6350,\n",
       "          1.6244, -0.8760, -0.4306,  0.7669,  0.4532, -0.1723,  0.0375, -1.7578,\n",
       "         -1.7196, -1.1633, -1.0312,  0.1418,  0.1402, -0.1191,  0.1061, -0.3969]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = transformer_model(src, tgt)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_CuTmoXPaYqd",
    "outputId": "791307c0-0beb-4be5-e28b-300089a552bf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
