{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Basic Shapes of the Transformer encoder for time series"
      ],
      "metadata": {
        "id": "oiu_4VcHVUHJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Layer -> Post Encoding -> Encoder Layer -> Encoder Layer"
      ],
      "metadata": {
        "id": "am3JjikEVZnM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YlA1JREiVolk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Instance of encoder layer\n",
        "encoder_layer = nn.TransformerEncoderLayer(d_model = 256, nhead = 8) #d_model is the input size\n",
        "encoder_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIU0yjz-VsUn",
        "outputId": "d2c7cb78-9ff2-437e-c8c5-05f3a2d7fb20"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerEncoderLayer(\n",
              "  (self_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "  (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "  (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "  (dropout1): Dropout(p=0.1, inplace=False)\n",
              "  (dropout2): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Data\n",
        "x = torch.randn(32, 256) # Batchsize x seqlen. seqlen must be equal to the embedded dimension of the transformer"
      ],
      "metadata": {
        "id": "lnSi58iwVzTD"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get output from encoder layer\n",
        "out_encoder_layer = encoder_layer(x)\n",
        "out_encoder_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKpgPRifV5Qd",
        "outputId": "c3f76104-cba2-4c1f-8bc8-0124d9a29c57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.1345,  0.1916, -0.3283,  ..., -0.9822,  0.8215, -1.0673],\n",
              "        [-0.1567,  0.4350, -1.7306,  ...,  1.8023,  0.3061, -1.3368],\n",
              "        [ 0.7932,  0.1927,  0.2961,  ..., -2.0422,  0.2612, -0.2270],\n",
              "        ...,\n",
              "        [ 0.6337,  1.1824,  1.2053,  ...,  0.2002, -0.1593,  0.1517],\n",
              "        [-0.3707,  1.7830, -1.8302,  ...,  1.3932, -0.7683,  0.0058],\n",
              "        [ 0.0623,  1.3671, -0.2881,  ...,  0.3810, -1.1351, -0.1194]],\n",
              "       grad_fn=<NativeLayerNormBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_encoder_layer.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np6mEEPGWHjA",
        "outputId": "83c5aee7-7413-491f-f3dc-708f6dff125d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Data 2\n",
        "\n",
        "x2 = torch.rand(32, 1, 185)\n",
        "x2 = nn.Linear(185, 256)(x2)\n",
        "out_encoder_layer2 = encoder_layer(x2)\n",
        "out_encoder_layer2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nR64jRqgWJrR",
        "outputId": "2d589e19-ba9a-40bb-e5d0-4b41dfdf52c6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 1, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Instancing the encoder\n",
        "num_layers = 6\n",
        "encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
        "encoder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsh6fug1WYdK",
        "outputId": "695d491d-18b2-4f74-af03-15ba392d4fee"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TransformerEncoder(\n",
              "  (layers): ModuleList(\n",
              "    (0-5): 6 x TransformerEncoderLayer(\n",
              "      (self_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
              "      )\n",
              "      (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout1): Dropout(p=0.1, inplace=False)\n",
              "      (dropout2): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_encoder = encoder(x)\n",
        "out_encoder.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GJwu-t0WiXS",
        "outputId": "397357d9-b62f-4a1f-ca56-e35d5c9dbeae"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}